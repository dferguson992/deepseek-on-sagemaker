{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c91ef53-0d3e-4e16-8b61-06b1fe3f6435",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker boto3 botocore -U\n",
    "# restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7e9072-1b58-45e3-9410-c2e913ff4b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DeepSeek-R1-Distill-Llama-8B on SageMaker\n",
    "# Ensure your Service Quota for ml.g5.2xlarge is at least 1\n",
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "\n",
    "try:\n",
    "\trole = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'deepseek-ai/DeepSeek-R1-Distill-Llama-8B',\n",
    "\t'SM_NUM_GPUS': json.dumps(1)\n",
    "}\n",
    "\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\timage_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"2.3.1\"),\n",
    "\tenv=hub,\n",
    "\trole=role, \n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1,\n",
    "\tinstance_type=\"ml.g5.2xlarge\",\n",
    "\tcontainer_startup_health_check_timeout=3600,\n",
    "  )\n",
    "  \n",
    "# send request\n",
    "predictor.predict({\n",
    "\t\"inputs\": \"Hi, what can you help me with?\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28367451-22e9-45aa-ad2e-ad384318c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DeepSeek-R1-Distill-Llama-70B on SageMaker Inferentia\n",
    "# Ensure your Service Quota for ml.inf2.48xlarge is at least 1\n",
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    role = iam.get_role(RoleName=\"sagemaker_execution_role\")[\"Role\"][\"Arn\"]\n",
    "\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "    \"HF_MODEL_ID\": \"deepseek-ai/DeepSeek-R1-Distill-Llama-70B\",\n",
    "    \"HF_NUM_CORES\": \"24\",\n",
    "    \"HF_AUTO_CAST_TYPE\": \"bf16\",\n",
    "    \"MAX_BATCH_SIZE\": \"4\",\n",
    "    \"MAX_INPUT_TOKENS\": \"3686\",\n",
    "    \"MAX_TOTAL_TOKENS\": \"4096\",\n",
    "}\n",
    "\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    image_uri=get_huggingface_llm_image_uri(\"huggingface-neuronx\", version=\"0.0.25\"),\n",
    "    env=hub,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.inf2.48xlarge\",\n",
    "    container_startup_health_check_timeout=3600,\n",
    "    volume_size=512,\n",
    ")\n",
    "\n",
    "# send request\n",
    "predictor.predict(\n",
    "    {\n",
    "        \"inputs\": \"What is is the capital of France?\",\n",
    "        \"parameters\": {\n",
    "            \"do_sample\": True,\n",
    "            \"max_new_tokens\": 128,\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_k\": 50,\n",
    "            \"top_p\": 0.95,\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
